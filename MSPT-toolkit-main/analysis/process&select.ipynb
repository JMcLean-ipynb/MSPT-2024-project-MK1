{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333351e-6c0e-4530-ae8a-8478c790562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 40272: 9 trajectories present.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #fails at making graph using fixinggraphs env\n",
    "import pandas as pd\n",
    "import trackpy\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import mspt.particle_fitting as fit\n",
    "import mspt.image_processing as img\n",
    "import mspt.particle_detection as detect\n",
    "import mspt.trajectory_analysis1 as traj\n",
    "import mspt.plotting as plot \n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "\n",
    "# Specify directory\n",
    "#directory = os.path.normpath(r'C:\\Users\\admin\\Desktop\\MSPT test') # set manually\n",
    "directory = img.directoryDialog(os.getcwd()) # or via dialog\n",
    "\n",
    "# Generate list of .mp or .h5 files to process\n",
    "filepaths_data = img.find_filepaths(directory, extension='mp', exclude=None)\n",
    "for file in filepaths_data:\n",
    "    print(file)\n",
    "    \n",
    "assert len(filepaths_data) > 0, 'Cannot find any HDF5 files to process in current directory'\n",
    "\n",
    "# General parameters\n",
    "batch_mode = True # Load mp file(s) on the fly without pop-up file dialog\n",
    "frame_range = [] # Restrict analysis to certain frames, e.g. [0, 2000]. To analyze whole movie, leave list empty.\n",
    "navg = 1 # Frame averaging, applied before background removal\n",
    "\n",
    "# Background removal\n",
    "mode = 'continuous_median' # Choose background removal strategy\n",
    "window_length = 1001 # Set median window length\n",
    "save_processed_movies = True # Save movies after background removal\n",
    "parallel = True # Use multiple cores to perform background substraction. Applies only if GPU=False\n",
    "GPU = False # Use GPU to perform background substraction (requires CUDA and pytorch). Applies only if parallel=False\n",
    "\n",
    "# Spot detection\n",
    "thresh = 0.00055 # Threshold paramter to mask candidate spots\n",
    "DoG_estimates={ 'T' : 0.1423, 's' : 2.1436, 'sigma' : 1.2921 } # Initial guesses for PSF fitting\n",
    "\n",
    "# Trajectory linking parameters\n",
    "dmax = 4. # Maximum displacement of particles per frame (in pixels)\n",
    "max_frames_to_vanish = 0 # Allow to link particles that where missed in these many frames\n",
    "minimum_trajectory_length = 5 # Only keep particle that exist for at least this many frames\n",
    "\n",
    "assert len(frame_range)==2 or len(frame_range)==0, 'frame_range is expected to be either of type [] or [int, int]'\n",
    "\n",
    "for filename in filepaths_data:\n",
    "    \n",
    "    # Apply continuous median background removal\n",
    "    frames, file = img.mp_reader(batch_mode=batch_mode,\n",
    "                                 file_to_load=filename,\n",
    "                                 frame_range=frame_range,\n",
    "                                 mode=mode,\n",
    "                                 navg=navg,\n",
    "                                 window_length=window_length,\n",
    "                                 parallel=parallel, \n",
    "                                 GPU=GPU)\n",
    "    \n",
    "    # Get name of video\n",
    "    name = os.path.splitext(os.path.basename(file))[0]\n",
    "    # Get current timestamp to prevent overwrite data\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Save processed movies to HDF5 file\n",
    "    if save_processed_movies:\n",
    "        saving_folder_movie = os.path.splitext(file)[0] + '_{}{}'.format(mode[11:], window_length)\n",
    "        processed_movie_file = os.path.join(saving_folder_movie,\n",
    "                                            os.path.split(saving_folder_movie)[1] + '.h5')\n",
    "        \n",
    "        if not os.path.exists(saving_folder_movie):\n",
    "            os.makedirs(saving_folder_movie)\n",
    "        \n",
    "        with h5py.File(processed_movie_file, 'w') as fn:\n",
    "            fn.create_dataset('frames', data=frames)\n",
    "            fn.create_dataset('window_length', data=window_length)\n",
    "            if frame_range:\n",
    "                fn.create_dataset('frame_range', data=frame_range)\n",
    "            else:\n",
    "                fn.create_dataset('frame_range', data=[0, frames.shape[0]])\n",
    "        print('Saved processed movies to {}'.format(processed_movie_file))\n",
    "\n",
    "        \n",
    "    # Detect and fit candidate spots\n",
    "    fitted_particles = fit.particle_fitter(frames,\n",
    "                                           halfsize=window_length//2,\n",
    "                                           thresh=thresh,\n",
    "                                           frame_range=[],\n",
    "                                           method='trust-ncg',\n",
    "                                           DoG_estimates=DoG_estimates)     \n",
    "    \n",
    "    # Create folder to save processed data\n",
    "    if save_processed_movies:\n",
    "        detections_folder = os.path.join(saving_folder_movie,\n",
    "                                         'thresh{}_fits{}'.format(thresh, timestamp))\n",
    "    else:\n",
    "        detections_folder = '{}_{}{}_thresh{}_fits{}'.format(os.path.splitext(file)[0], # Remove file extension\n",
    "                                                             mode[11:], # Remove 'continuous_'\n",
    "                                                             window_length,\n",
    "                                                             thresh,\n",
    "                                                             timestamp)   \n",
    "        \n",
    "    if not os.path.exists(detections_folder):\n",
    "        os.makedirs(detections_folder)    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # Save particle detections as csv file\n",
    "    if len(frame_range) == 0:\n",
    "        csv_name = '{}_all_frames'.format(name)\n",
    "        detections_file = os.path.join(detections_folder,\n",
    "                                       csv_name + '.csv')  \n",
    "    else:\n",
    "        csv_name = '{}_frames{}-{}'.format(name, frame_range[0], frame_range[1])\n",
    "        detections_file = os.path.join(detections_folder,\n",
    "                                       csv_name + '.csv')\n",
    "    \n",
    "    fitted_particles.to_csv(detections_file)\n",
    "    print('Saved trajectory list to {}'.format(detections_file))\n",
    "\n",
    "    \n",
    "    # Link trajectories\n",
    "    linked_trajectories = trackpy.link_df(fitted_particles, search_range=dmax, memory=max_frames_to_vanish)\n",
    "    linked_trajectories = linked_trajectories.sort_values(by=['particle', 'frame'])\n",
    "    trajectories_lenfilt = trackpy.filter_stubs(linked_trajectories, minimum_trajectory_length)\n",
    "\n",
    "    trajectories_folder = os.path.join(detections_folder,\n",
    "                                       'dmax{}_mem{}_fits{}'.format(dmax, max_frames_to_vanish, timestamp))\n",
    "    \n",
    "    if not os.path.exists(trajectories_folder):\n",
    "        os.makedirs(trajectories_folder)\n",
    "\n",
    "    trajectories_file = os.path.join(trajectories_folder,\n",
    "                                     '{}_trajectories.csv'.format(csv_name))\n",
    "\n",
    "#     # Workaround in Windows if filename is too long\n",
    "#     if len(trajectories_file) >= 260: #max is 260\n",
    "#         trajectories_file = '\\\\\\\\?\\\\'+ trajectories_file\n",
    "\n",
    "    trajectories_lenfilt.to_csv(trajectories_file)\n",
    "    print('Saved trajectory list to {}'.format(trajectories_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da69be-defa-4441-92b1-6e91249b5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = os.path.normpath(r'C:\\Users\\admin\\Desktop\\MSPT test\\001_sample_median1001.h5') # set manually\n",
    "file = img.fileDialog(os.getcwd()) # or via dialog\n",
    "assert os.path.isfile(file), 'File \"{}\" does not exist'.format(file)\n",
    "\n",
    "# Load processed movies from HDF5 file\n",
    "with h5py.File(file, 'r') as h5_file:\n",
    "    frames = np.asarray(h5_file['frames']).copy()\n",
    "    window_length = np.asarray(h5_file['window_length']).copy()\n",
    "    frame_range = np.asarray(h5_file['frame_range']).copy()\n",
    "    \n",
    "print('Loaded processed movie {}'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb67a79-f211-4618-9d18-1a33ffbc08a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
